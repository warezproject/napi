import json
from pathlib import Path
from urllib.parse import quote_plus
import requests
import streamlit as st

# -----------------------------
# ê¸°ë³¸ ì„¤ì •
# -----------------------------
st.set_page_config(page_title="êµ­ê°€ì •ë³´ì •ì±…í˜‘ì˜íšŒ TEST", layout="wide")

st.title("êµ­ê°€ì •ë³´ì •ì±…í˜‘ì˜íšŒ TEST")
st.caption("ì „ë‚¨ì—°êµ¬ì› ë¡œì»¬ ë°ì´í„° + êµ­ë¦½ì¤‘ì•™ë„ì„œê´€ API ì„œë²„ì‚¬ì´ë“œ ê²€ìƒ‰ (ìƒì„¸í˜ì´ì§€ ì§ë§í¬)")

# -----------------------------
# ì…ë ¥ UI
# -----------------------------
with st.form("search_form", clear_on_submit=False):
    kw = st.text_input("ë„ì„œ ì œëª©ì„ ì…ë ¥í•˜ì„¸ìš”", value="", placeholder="ì˜ˆ: ë”¥ëŸ¬ë‹, ë¨¸ì‹ ëŸ¬ë‹, ì¸ê³µì§€ëŠ¥ â€¦")
    submitted = st.form_submit_button("ê²€ìƒ‰")

# -----------------------------
# í—¬í¼ í•¨ìˆ˜
# -----------------------------
@st.cache_data(show_spinner=False)
def load_jndi_json(json_path: Path):
    if not json_path.exists():
        return [], {"exists": False, "count": 0, "path": str(json_path)}
    try:
        data = json.loads(json_path.read_text(encoding="utf-8"))
        return data, {"exists": True, "count": len(data), "path": str(json_path)}
    except Exception as e:
        st.warning(f"ì „ë‚¨ì—°êµ¬ì› JSON ì½ê¸° ì˜¤ë¥˜: {e}")
        return [], {"exists": True, "count": 0, "path": str(json_path)}

def search_jndi(records, keyword: str):
    if not keyword:
        return []
    key_candidates = ("ì„œëª…", "ì„œëª… ", "ì„œëª…(êµ­ë¬¸)", "ìë£Œëª…", "ì œëª©", "Title", "title", "TITLE")
    low_kw = keyword.casefold().strip()
    matched = []
    for rec in records:
        for k in key_candidates:
            v = rec.get(k)
            if isinstance(v, str) and low_kw in v.casefold().strip():
                matched.append(rec)
                break
    return matched

def _build_detail_link(rec: dict) -> str:
    """
    NLK ìƒì„¸í˜ì´ì§€ ì§ë§í¬ë¥¼ ë§Œë“ ë‹¤.
    ìš°ì„ ìˆœìœ„: ISBN -> CN/CONTROL_NO(ì„œì§€ë²ˆí˜¸ ê³„ì—´) -> (ìµœí›„) ì œëª© ê²€ìƒ‰
    """
    # ì–´ë–¤ í‚¤ë¡œ ì˜¤ëŠ”ì§€ ì¼€ì´ìŠ¤ê°€ ë‹¬ë¼ ë‹¤ì–‘í•œ í›„ë³´ë¥¼ ë³¸ë‹¤
    isbn = (rec.get("ISBN") or rec.get("Isbn") or rec.get("isbn") or "").strip()
    cn = (
        rec.get("CN")
        or rec.get("ControlNo")
        or rec.get("CONTROL_NO")
        or rec.get("CONTROLNO")
        or rec.get("DOCID")
        or rec.get("DOC_ID")
        or rec.get("BIB_ID")
        or ""
    )
    title = (rec.get("TITLE") or rec.get("Title") or rec.get("title") or "").strip()

    if isbn:
        return f"https://www.nl.go.kr/search/SearchDetail.do?isbn={quote_plus(isbn)}"
    if cn:
        return f"https://www.nl.go.kr/search/SearchDetail.do?cn={quote_plus(str(cn))}"
    # ìµœí›„: í†µí•©ê²€ìƒ‰ í˜ì´ì§€ë¡œ í´ë°±
    if title:
        return f"https://www.nl.go.kr/search/searchResult.jsp?category=total&kwd={quote_plus(title)}"
    return "https://www.nl.go.kr"

def _normalize_docs(docs):
    """
    docs(list of dict)ë¥¼ ë°›ì•„ ê° ì•„ì´í…œì— DETAIL_LINKë¥¼ ì£¼ì…í•´ ë°˜í™˜.
    """
    out = []
    for d in docs or []:
        try:
            d = dict(d)  # ë°©ì–´ì  ë³µì‚¬
        except Exception:
            continue
        d["DETAIL_LINK"] = _build_detail_link(d)
        out.append(d)
    return out

def call_nlk_api(keyword: str):
    """Cloudflare Worker í”„ë¡ì‹œë§Œ ì‚¬ìš©(DETAIL_LINKëŠ” Workerê°€ ì£¼ì…)"""
    if not keyword:
        return []

    proxy_base = st.secrets.get("NLK_PROXY_BASE", "").rstrip("/")
    if not proxy_base:
        st.error("Secretsì— NLK_PROXY_BASEê°€ ì—†ìŠµë‹ˆë‹¤. Cloudflare Worker ì£¼ì†Œë¥¼ NLK_PROXY_BASEë¡œ ì¶”ê°€í•˜ì„¸ìš”.")
        return []

    try:
        r = requests.get(
            f"{proxy_base}/",
            params={"title": keyword, "page_no": 1, "page_size": 10},
            timeout=10,
            headers={"User-Agent": "Mozilla/5.0 (Streamlit App via Proxy)"}
        )
        data = r.json()
        docs = data.get("docs", []) if isinstance(data, dict) else data
        return docs if isinstance(docs, list) else []
    except Exception as e:
        st.error(f"í”„ë¡ì‹œ í˜¸ì¶œ ì˜¤ë¥˜: {e}")
        return []


def aladin_cover_from_isbn(isbn: str):
    """ê°„ë‹¨ ì»¤ë²„ URL ì¶”ì •(ì„±ê³µ ë³´ì¥ X) - ì—†ìœ¼ë©´ ë¹ˆ ë¬¸ìì—´"""
    if not isbn:
        return ""
    return f"https://image.aladin.co.kr/product/{isbn[-3:]}/{isbn[-5:]}cover.jpg"

# -----------------------------
# ë°ì´í„° ë¡œë“œ (ì‹¤ì œ íŒŒì¼ëª…ì— ë§ì¶¤)
# -----------------------------
# â€» ì´ì „ì— 'static/ì „ë‚¨ì—°êµ¬ì›.json'ì„ ì“°ì…¨ë‹¤ë©´ íŒŒì¼ëª…ì„ í†µì¼í•˜ì„¸ìš”.
jndi_all, jndi_meta = load_jndi_json(Path("static/ì „ë‚¨ì—°êµ¬ì›.json"))

# -----------------------------
# ê²€ìƒ‰ ì‹¤í–‰
# -----------------------------
if submitted:
    # ì „ë‚¨ì—°êµ¬ì› ê²€ìƒ‰
    jndi_hits = search_jndi(jndi_all, kw)

    # NLK API ê²€ìƒ‰ (ìƒì„¸ ë§í¬ í¬í•¨)
    nlk_docs = call_nlk_api(kw)

    # -----------------------------
    # ê²°ê³¼ í‘œì‹œ
    # -----------------------------
    st.write("---")
    cols = st.columns([1, 1])

    # ì „ë‚¨ì—°êµ¬ì›
    with cols[0]:
        st.subheader("ì „ë‚¨ì—°êµ¬ì› ê²€ìƒ‰ ê²°ê³¼")
        st.caption(f"ë¡œì»¬ ë°ì´í„°: ì¡´ì¬={jndi_meta['exists']} Â· ê²½ë¡œ={jndi_meta['path']} Â· ì´ {jndi_meta['count']}ê±´")
        if jndi_hits:
            for b in jndi_hits:
                with st.container(border=True):
                    title = b.get('ì„œëª…') or b.get('ì„œëª… ') or b.get('Title') or b.get('ì œëª©') or ''
                    st.markdown(f"**{title}**")
                    st.caption(
                        f"ì €ì: {b.get('ì €ì','ì •ë³´ ì—†ìŒ')} Â· "
                        f"ë°œí–‰ì: {b.get('ë°œí–‰ì','ì •ë³´ ì—†ìŒ')} Â· "
                        f"ë°œí–‰ë…„ë„: {b.get('ë°œí–‰ë…„ë„','ì •ë³´ ì—†ìŒ')}"
                    )
                    regno = b.get("ë“±ë¡ë²ˆí˜¸", "")
                    if regno:
                        st.code(f"ë“±ë¡ë²ˆí˜¸: {regno}", language="text")
        else:
            st.info("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")

    # êµ­ë¦½ì¤‘ì•™ë„ì„œê´€
    with cols[1]:
        st.subheader("êµ­ë¦½ì¤‘ì•™ë„ì„œê´€ ê²€ìƒ‰ ê²°ê³¼")
        if nlk_docs:
            for d in nlk_docs:
                with st.container(border=True):
                    title = d.get("TITLE", "ì œëª© ì—†ìŒ")
                    # ğŸ”´ ì—¬ê¸°! DETAIL_LINK ìš°ì„  ì‚¬ìš©
                    link = d.get("DETAIL_LINK")
                    if not link:  # í˜¹ì‹œ Workerê°€ ëª» ë„£ì–´ì¤¬ì„ ë•Œë§Œ ìµœí›„ fallback
                        isbn = (d.get("ISBN") or "").strip()
                        cn = (d.get("CN") or d.get("CONTROL_NO") or d.get("CONTROLNO") or "")
                        if isbn:
                            link = f"https://www.nl.go.kr/search/SearchDetail.do?isbn={quote_plus(isbn)}"
                        elif cn:
                            link = f"https://www.nl.go.kr/search/SearchDetail.do?cn={quote_plus(str(cn))}"
                        else:
                            link = f"https://www.nl.go.kr/search/searchResult.jsp?category=total&kwd={quote_plus(title)}"

                    st.markdown(f"**[{title}]({link})**")
                    st.caption(
                        f"ì €ì: {d.get('AUTHOR','ì •ë³´ ì—†ìŒ')} Â· "
                        f"ì¶œíŒì‚¬: {d.get('PUBLISHER','ì •ë³´ ì—†ìŒ')} Â· "
                        f"ë°œí–‰ë…„ë„: {d.get('PUBLISH_YEAR','ì •ë³´ ì—†ìŒ')}"
                    )
                    isbn = (d.get("ISBN") or "").strip()
                    if isbn:
                        st.code(f"ISBN: {isbn}", language="text")
                        cover = aladin_cover_from_isbn(isbn)
                        if cover:
                            st.image(cover, use_container_width=True)
        else:
            st.info("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")

